{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass education_level  education-num       marital-status  \\\n",
       "0   39          State-gov       Bachelors           13.0        Never-married   \n",
       "1   50   Self-emp-not-inc       Bachelors           13.0   Married-civ-spouse   \n",
       "\n",
       "         occupation    relationship    race    sex  capital-gain  \\\n",
       "0      Adm-clerical   Not-in-family   White   Male        2174.0   \n",
       "1   Exec-managerial         Husband   White   Male           0.0   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country income  \n",
       "0           0.0            40.0   United-States  <=50K  \n",
       "1           0.0            13.0   United-States  <=50K  "
      ]
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score, accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.base import clone\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv(\"census.csv\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target label and map income to 0 and 1\n",
    "X = data.drop('income', axis = 1)\n",
    "y = data['income']\n",
    "y_mapped = pd.DataFrame(y.map({'<=50K': 0, '>50K': 1}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncoderTransform(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        encoded_features = pd.DataFrame(pd.get_dummies(X))\n",
    "        return encoded_features\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return self.transform(X).columns.tolist()\n",
    "\n",
    "class LogTransform(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        log_X = pd.DataFrame(np.log1p(X))\n",
    "        return log_X\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return self.transform(X).columns.tolist()\n",
    "    \n",
    "class ScaleTransform(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        \n",
    "    def transform(self, X, **transform_params):\n",
    "        return pd.DataFrame(self.scaler.transform(X))\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.scaler = self.scaler.fit(X.astype(float))\n",
    "        return self\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return self.transform(X).columns.tolist()\n",
    "\n",
    "class ModelTransformer(TransformerMixin):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        self.model.fit(*args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return pd.DataFrame(self.model.predict(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabela/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest : 0.6836744983361903\n",
      "AdaBoost : 0.7245508982035928\n",
      "SVC : 0.6744771706996605\n"
     ]
    }
   ],
   "source": [
    "skewed = ['capital-gain', 'capital-loss']\n",
    "numerical = ['age', 'education-num', 'hours-per-week']\n",
    "categorical = ['workclass', 'education_level', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "\n",
    "log_and_scale_transformer = ColumnTransformer(\n",
    "    [\n",
    "     (\"log_and_scale\", Pipeline([('log', LogTransform()),\n",
    "                                 ('scale', ScaleTransform())]), skewed), \n",
    "     (\"scaler\", ScaleTransform(), numerical)\n",
    "    ], remainder='drop');\n",
    "\n",
    "encoder_transformer = ColumnTransformer(\n",
    "    [\n",
    "     (\"encode\", OneHotEncoderTransform(), categorical)\n",
    "    ], remainder='drop')\n",
    "\n",
    "preprocessing = Pipeline([\n",
    "    ('preprocessing', FeatureUnion([\n",
    "        ('numerical_features', log_and_scale_transformer),\n",
    "        ('categorical_features', encoder_transformer),\n",
    "    ]))\n",
    "])\n",
    "\n",
    "classifier_pipeline = Pipeline([\n",
    "    ('classifiers', FeatureUnion([\n",
    "        ('RF', ModelTransformer(RandomForestClassifier(random_state = 42))),\n",
    "        ('Ada', ModelTransformer(AdaBoostClassifier(random_state = 42))),\n",
    "        ('SVC', ModelTransformer(SVC(random_state = 42, gamma='auto')))\n",
    "    ]))\n",
    "])\n",
    "\n",
    "# apply preprocessing pipeline\n",
    "X_transformed = preprocessing.fit_transform(X)\n",
    "\n",
    "# separate data in training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y_mapped, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# initial model evaluation to choose the best model\n",
    "classifier_pipeline.fit(X_train, y_train.values.ravel())\n",
    "vec_preds = classifier_pipeline.transform(X_test)\n",
    "classifier_labels = ['Random Forest', 'AdaBoost', 'SVC'] \n",
    "df_preds = pd.DataFrame(vec_preds)\n",
    "df_preds.columns = classifier_labels\n",
    "for clf in classifier_labels:\n",
    "    print(clf,':', fbeta_score(y_test['income'], df_preds[clf], beta = 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "Accuracy score on testing data: 0.8576\n",
      "F-score on testing data: 0.7246\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final accuracy score on the testing data: 0.8663\n",
      "Final F-score on the testing data: 0.7425\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('ada', AdaBoostClassifier(random_state = 42))])\n",
    "\n",
    "# display possible params: pipe.get_params().keys()\n",
    "\n",
    "parameters = { 'ada__n_estimators': [100, 200, 300], \n",
    "              'ada__learning_rate': [0.01, 0.1, 1]}\n",
    "\n",
    "scorer = make_scorer(fbeta_score, beta = 0.5)\n",
    "\n",
    "grid_obj = GridSearchCV(pipe, parameters, scoring = scorer, cv = 5)\n",
    "\n",
    "grid_fit = grid_obj.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# get the predictions from unoptimized and current model\n",
    "predictions = df_preds['AdaBoost']\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use recursive feature elimination to check score on reduced feature set\n",
    "selector = RFE(best_clf.named_steps['ada'], 5, step=0.10) # reduce 10% at each step\n",
    "selector = selector.fit(X_train, y_train.values.ravel())\n",
    "most_important_columns = selector.support_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['capital-gain', 'capital-loss', 'age', 'education-num',\n",
       "       'hours-per-week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 900,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a df from X_train and set columns names\n",
    "columns_labels_numerical = ['capital-gain', 'capital-loss'] + ['age','education-num','hours-per-week']\n",
    "columns_labels_encoded = preprocessing.named_steps['preprocessing'].transformer_list[1][1].transformers[0][1].get_feature_names()\n",
    "df_X_train = pd.DataFrame(X_train)\n",
    "df_X_train.columns = columns_labels_numerical + columns_labels_encoded[5:]\n",
    "\n",
    "# get name of most important columns\n",
    "df_X_train.columns[most_important_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model trained on full data\n",
      "------\n",
      "Accuracy on testing data: 0.8663\n",
      "F-score on testing data: 0.7425\n",
      "\n",
      "Final Model trained on reduced data\n",
      "------\n",
      "Accuracy on testing data: 0.8404\n",
      "F-score on testing data: 0.6973\n"
     ]
    }
   ],
   "source": [
    "# get indices of most important features\n",
    "idx = np.where(selector.support_)[0]\n",
    "\n",
    "# Reduce the feature space\n",
    "X_train_reduced = X_train[:,idx]\n",
    "X_test_reduced = X_test[:,idx]\n",
    "\n",
    "# Train on the \"best\" model found from grid search earlier\n",
    "clf = (clone(best_clf)).fit(X_train_reduced, y_train.values.ravel())\n",
    "\n",
    "# Make new predictions\n",
    "reduced_predictions = clf.predict(X_test_reduced)\n",
    "\n",
    "# Report scores from the final model using both versions of data\n",
    "print(\"Final Model trained on full data\\n------\")\n",
    "print(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "print(\"\\nFinal Model trained on reduced data\\n------\")\n",
    "print(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, reduced_predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, reduced_predictions, beta = 0.5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
